{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83501cb3-32a0-4ad4-9b91-87adfd3bebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33681425-af96-409d-ad8e-129093b48b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rucke\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # This prints the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b552be97-136c-4ae6-a824-80c6938ff3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: C:\\Users\\rucke\\Downloads\\Cleaned_Payer_Reimbursement_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from the Downloads folder\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\Payer_Reimbursement_Data.csv\"\n",
    "payer_data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert DOS (Date of Service) to datetime\n",
    "payer_data[\"DOS\"] = pd.to_datetime(payer_data[\"DOS\"])\n",
    "\n",
    "# Drop duplicates and missing values\n",
    "payer_data.drop_duplicates(inplace=True)\n",
    "payer_data.dropna(inplace=True)\n",
    "\n",
    "# Save cleaned file in the same folder\n",
    "cleaned_path = r\"C:\\Users\\rucke\\Downloads\\Cleaned_Payer_Reimbursement_Data.csv\"\n",
    "payer_data.to_csv(cleaned_path, index=False)\n",
    "\n",
    "print(\"Cleaned data saved to:\", cleaned_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8666bf61-fb67-4df5-9b9b-b227e0cde682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PayerID  PayerType  TotalClaims  ChargesBilled  AmountReimbursed  \\\n",
      "0     1001   Medicare          500         300000            200000   \n",
      "1     1002   Self-Pay          200         200000            140000   \n",
      "2     1003   Medicaid          150         150000            100000   \n",
      "3     1004  Insurance          250         100000             70000   \n",
      "4     1005  Insurance          150          90000             60000   \n",
      "\n",
      "   DeniedClaims  ReimbursementRate         DOS  \n",
      "0            50               0.67  2023-01-09  \n",
      "1            10               0.75  2023-01-11  \n",
      "2            25               0.67  2023-02-02  \n",
      "3             5               0.67  2023-02-13  \n",
      "4             5               0.67  2023-03-02  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   PayerID            40 non-null     int64  \n",
      " 1   PayerType          40 non-null     object \n",
      " 2   TotalClaims        40 non-null     int64  \n",
      " 3   ChargesBilled      40 non-null     int64  \n",
      " 4   AmountReimbursed   40 non-null     int64  \n",
      " 5   DeniedClaims       40 non-null     int64  \n",
      " 6   ReimbursementRate  40 non-null     float64\n",
      " 7   DOS                40 non-null     object \n",
      "dtypes: float64(1), int64(5), object(2)\n",
      "memory usage: 2.6+ KB\n",
      "None\n",
      "           PayerID  TotalClaims  ChargesBilled  AmountReimbursed  \\\n",
      "count    40.000000    40.000000      40.000000         40.000000   \n",
      "mean   1020.500000   273.750000  168000.000000     116125.000000   \n",
      "std      11.690452   126.586091  101815.569813      70394.834273   \n",
      "min    1001.000000   100.000000       0.000000          0.000000   \n",
      "25%    1010.750000   150.000000  100000.000000      70000.000000   \n",
      "50%    1020.500000   275.000000  150000.000000     100000.000000   \n",
      "75%    1030.250000   362.500000  228750.000000     158125.000000   \n",
      "max    1040.000000   500.000000  500000.000000     350000.000000   \n",
      "\n",
      "       DeniedClaims  ReimbursementRate  \n",
      "count     40.000000          40.000000  \n",
      "mean      16.750000           0.666500  \n",
      "std       11.009902           0.158625  \n",
      "min        5.000000           0.000000  \n",
      "25%       10.000000           0.670000  \n",
      "50%       15.000000           0.685000  \n",
      "75%       21.250000           0.750000  \n",
      "max       50.000000           0.750000  \n",
      "PayerID              0\n",
      "PayerType            0\n",
      "TotalClaims          0\n",
      "ChargesBilled        0\n",
      "AmountReimbursed     0\n",
      "DeniedClaims         0\n",
      "ReimbursementRate    0\n",
      "DOS                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\Cleaned_Payer_Reimbursement_Data.csv\"\n",
    "payer_data = pd.read_csv(file_path)\n",
    "\n",
    "# Initial checks\n",
    "print(payer_data.head())  # View first 5 rows\n",
    "print(payer_data.info())  # Check data types, nulls\n",
    "print(payer_data.describe())  # Get summary statistics\n",
    "print(payer_data.isnull().sum())  # Count missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850ec5b4-517b-445e-8b3d-e12549d4a382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to: C:\\Users\\rucke\\Downloads\\Filtered_Payer_Reimbursement_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Select only necessary columns\n",
    "columns_to_keep = ['PayerID', 'PayerType', 'ChargesBilled',\n",
    "       'AmountReimbursed', 'ReimbursementRate', 'DOS']\n",
    "filtered_data = payer_data[columns_to_keep]\n",
    "\n",
    "# Save the filtered data before SQL upload\n",
    "filtered_path = r\"C:\\Users\\rucke\\Downloads\\Filtered_Payer_Reimbursement_Data.csv\"\n",
    "filtered_data.to_csv(filtered_path, index=False)\n",
    "\n",
    "print(\"Filtered data saved to:\", filtered_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7139b5-6e33-4a66-b4d0-764770626053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PayerID  PayerType  ChargesBilled  AmountReimbursed  ReimbursementRate  \\\n",
      "0     1001   Medicare         300000            200000               0.67   \n",
      "1     1002   Self-Pay         200000            140000               0.75   \n",
      "2     1003   Medicaid         150000            100000               0.67   \n",
      "3     1004  Insurance         100000             70000               0.67   \n",
      "4     1005  Insurance          90000             60000               0.67   \n",
      "\n",
      "          DOS  \n",
      "0  2023-01-09  \n",
      "1  2023-01-11  \n",
      "2  2023-02-02  \n",
      "3  2023-02-13  \n",
      "4  2023-03-02  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   PayerID            40 non-null     int64  \n",
      " 1   PayerType          40 non-null     object \n",
      " 2   ChargesBilled      40 non-null     int64  \n",
      " 3   AmountReimbursed   40 non-null     int64  \n",
      " 4   ReimbursementRate  40 non-null     float64\n",
      " 5   DOS                40 non-null     object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 2.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data.head())\n",
    "print(filtered_data.info())  # Check data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57592528-357c-4d9c-80cd-d7b24f269d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.37)\n",
      "Requirement already satisfied: pyodbc in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rucke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy pyodbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a06850-a502-4012-99f4-6098ba7618f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully uploaded to SQL Server!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, Float, NVARCHAR, DateTime\n",
    "import pyodbc\n",
    "\n",
    "# Load the cleaned data\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\Filtered_Payer_Reimbursement_Data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert DOS column to datetime\n",
    "df[\"DOS\"] = pd.to_datetime(df[\"DOS\"])\n",
    "\n",
    "# Connect to SQL Server (ensure driver is correct)\n",
    "server = \"localhost\\\\SQLEXPRESS\"\n",
    "database = \"EMS_Analytics\"\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Define column data types using SQLAlchemy types\n",
    "dtype_mapping = {\n",
    "    \"PayerID\": Integer(),\n",
    "    \"PayerType\": NVARCHAR(255),\n",
    "    \"ChargesBilled\": Float(),\n",
    "    \"AmountReimbursed\": Float(),\n",
    "    \"ReimbursementRate\": Float(),\n",
    "    \"DOS\": DateTime()\n",
    "}\n",
    "\n",
    "# Upload data to SQL Server\n",
    "try:\n",
    "    df.to_sql(\"Payer_Reimbursement_Data\", con=engine, if_exists=\"replace\", index=False, dtype=dtype_mapping)\n",
    "    print(\"✅ Data successfully uploaded to SQL Server!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error uploading data: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91add1b5-0da7-4b58-8b92-aae3dc68849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import and Load EMS data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c176135-4582-44fa-b223-c16be8a861d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: C:\\Users\\rucke\\Downloads\\Cleaned_EMS_Incident_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from the Downloads folder\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\EMS_Incident_Data.csv\"\n",
    "payer_data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates and missing values\n",
    "payer_data.drop_duplicates(inplace=True)\n",
    "payer_data.dropna(inplace=True)\n",
    "\n",
    "# Save cleaned file in the same folder\n",
    "cleaned_path = r\"C:\\Users\\rucke\\Downloads\\Cleaned_EMS_Incident_Data.csv\"\n",
    "payer_data.to_csv(cleaned_path, index=False)\n",
    "\n",
    "print(\"Cleaned data saved to:\", cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e1c67f-2c89-4f8b-9d68-1e2c552a4339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [IncidentID, Zone, CallReceivedTime, OnSceneTime, HospitalArrivalTime, Longitude, Latitude]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   IncidentID           0 non-null      int64  \n",
      " 1   Zone                 0 non-null      object \n",
      " 2   CallReceivedTime     0 non-null      object \n",
      " 3   OnSceneTime          0 non-null      object \n",
      " 4   HospitalArrivalTime  0 non-null      object \n",
      " 5   Longitude            0 non-null      float64\n",
      " 6   Latitude             0 non-null      float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 0.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(payer_data.head())\n",
    "print(payer_data.info())  # Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4716c766-0c7f-41c0-8844-c659fd865396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully uploaded to SQL Server!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, Float, NVARCHAR, DateTime\n",
    "import pyodbc\n",
    "\n",
    "# Load the cleaned data\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\EMS_Incident_Data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert datetime columns to proper format\n",
    "date_columns = [\"CallReceivedTime\", \"OnSceneTime\", \"HospitalArrivalTime\"]\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")  # Convert and handle errors\n",
    "\n",
    "# Connect to SQL Server (ensure driver is correct)\n",
    "server = \"localhost\\\\SQLEXPRESS\"\n",
    "database = \"EMS_Analytics\"\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Define column data types for SQL\n",
    "dtype_mapping = {\n",
    "    \"IncidentID\": Integer(),\n",
    "    \"Zone\": NVARCHAR(255),\n",
    "    \"CallReceivedTime\": DateTime(),\n",
    "    \"OnSceneTime\": DateTime(),\n",
    "    \"HospitalArrivalTime\": DateTime(),\n",
    "    \"Longitude\": Float(),\n",
    "    \"Latitude\": Float()\n",
    "}\n",
    "\n",
    "# Upload data to SQL Server\n",
    "try:\n",
    "    df.to_sql(\"EMS_Incident_Data\", con=engine, if_exists=\"replace\", index=False, dtype=dtype_mapping)\n",
    "    print(\"✅ Data successfully uploaded to SQL Server!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error uploading data: {e}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f813eb2-2008-4ce7-bbc5-e399715a5b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProcedureID  HCPCS                 HCPCS_Description APC_Group  \\\n",
      "0        10001  A0425  Ground mileage, per statute mile  APC_5001   \n",
      "1        10002  A0426                    ALS assessment  APC_5002   \n",
      "2        10003  A0427          ALS, emergency transport  APC_5002   \n",
      "3        10004  A0428                BLS, non-emergency  APC_5001   \n",
      "4        10005  A0429          BLS, emergency transport  APC_5001   \n",
      "\n",
      "  Level_of_Service Transport_Type ICD10_Code  ICD10_Description  \n",
      "0              BLS      Transport      I21.9       Heart Attack  \n",
      "1             ALS1   No Transport      J44.1  COPD Exacerbation  \n",
      "2             ALS1      Emergency        R55            Syncope  \n",
      "3              BLS  Non-Emergency        I10       Hypertension  \n",
      "4              BLS      Emergency      I21.9       Heart Attack  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   ProcedureID        40 non-null     int64 \n",
      " 1   HCPCS              40 non-null     object\n",
      " 2   HCPCS_Description  40 non-null     object\n",
      " 3   APC_Group          40 non-null     object\n",
      " 4   Level_of_Service   40 non-null     object\n",
      " 5   Transport_Type     40 non-null     object\n",
      " 6   ICD10_Code         40 non-null     object\n",
      " 7   ICD10_Description  40 non-null     object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 2.6+ KB\n",
      "None\n",
      "        ProcedureID\n",
      "count     40.000000\n",
      "mean   10020.500000\n",
      "std       11.690452\n",
      "min    10001.000000\n",
      "25%    10010.750000\n",
      "50%    10020.500000\n",
      "75%    10030.250000\n",
      "max    10040.000000\n",
      "ProcedureID          0\n",
      "HCPCS                0\n",
      "HCPCS_Description    0\n",
      "APC_Group            0\n",
      "Level_of_Service     0\n",
      "Transport_Type       0\n",
      "ICD10_Code           0\n",
      "ICD10_Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\APC_DX_Mapping.csv\"\n",
    "payer_data = pd.read_csv(file_path)\n",
    "\n",
    "# Initial checks\n",
    "print(payer_data.head())  # View first 5 rows\n",
    "print(payer_data.info())  # Check data types, nulls\n",
    "print(payer_data.describe())  # Get summary statistics\n",
    "print(payer_data.isnull().sum())  # Count missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ff8d2b-ec16-486f-b9ab-f9db784586c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Integer, NVARCHAR\n",
    "import pyodbc\n",
    "\n",
    "# Load your DataFrame\n",
    "file_path = r\"C:\\Users\\rucke\\Downloads\\APC_DX_Mapping.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert data types\n",
    "df[\"ProcedureID\"] = df[\"ProcedureID\"].astype(int)\n",
    "df[\"HCPCS\"] = df[\"HCPCS\"].astype(str).str.strip()\n",
    "df[\"HCPCS_Description\"] = df[\"HCPCS_Description\"].astype(str).str.strip()\n",
    "df[\"APC_Group\"] = df[\"APC_Group\"].astype(str).str.strip()\n",
    "df[\"Level_of_Service\"] = df[\"Level_of_Service\"].astype(str).str.strip()\n",
    "df[\"Transport_Type\"] = df[\"Transport_Type\"].astype(str).str.strip()\n",
    "df[\"ICD10_Code\"] = df[\"ICD10_Code\"].astype(str).str.strip()\n",
    "df[\"ICD10_Description\"] = df[\"ICD10_Description\"].astype(str).str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8168278e-b557-4da0-b2c6-68a9b40dd92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully uploaded to SQL Server!\n"
     ]
    }
   ],
   "source": [
    "# Define SQL Server connection (Ensure you have the correct driver installed)\n",
    "server = \"localhost\\\\SQLEXPRESS\"\n",
    "database = \"EMS_Analytics\"\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Define SQLAlchemy dtype mapping\n",
    "dtype_mapping = {\n",
    "    \"ProcedureID\": Integer(),\n",
    "    \"HCPCS\": NVARCHAR(10),\n",
    "    \"HCPCS_Description\": NVARCHAR(255),\n",
    "    \"APC_Group\": NVARCHAR(50),\n",
    "    \"Level_of_Service\": NVARCHAR(50),\n",
    "    \"Transport_Type\": NVARCHAR(50),\n",
    "    \"ICD10_Code\": NVARCHAR(10),\n",
    "    \"ICD10_Description\": NVARCHAR(255),\n",
    "}\n",
    "\n",
    "# Upload DataFrame to SQL Server\n",
    "try:\n",
    "    df.to_sql(\"APC_DX_Mapping\", con=engine, if_exists=\"replace\", index=False, dtype=dtype_mapping)\n",
    "    print(\"✅ Data successfully uploaded to SQL Server!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error uploading data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ec45e-f3c3-468c-b5af-0846981b61dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
